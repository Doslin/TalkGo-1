# 第 2 阶段课程笔记

## 07 | 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（上）

一旦父进程没有处理子进程的终止，还一直保持运行状态，那么子进程就会一直处于僵尸状态。大量的僵尸进程会用尽 PID 进程号，导致新进程不能创建，所以这种情况一定要避免。

思考：

工作中就遇到这个问题，软件看门狗出现异常，频繁启动后台业务进程，导致进程号等资源用尽，系统瘫痪只能重启恢复。



## 08 | 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（下）

iowait 高不一定代表 I/O 有性能瓶颈。当系统中只有 I/O 类型的进程在运行时，iowait 也会很高，但实际上，磁盘的读写远没有达到性能瓶颈的程度。

因此，碰到 iowait 升高时，需要先用 dstat、pidstat 等工具，确认是不是磁盘 I/O 的问题，然后再找是哪些进程导致了 I/O。





## 09 | 基础篇：怎么理解Linux软中断？

Linux 将中断处理过程分成了两个阶段，也就是上半部和下半部：

上半部用来快速处理中断，它在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作。

下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行。

这两个阶段你也可以这样理解：

**上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行；**

**而下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。**

如何查看？

**/proc/softirqs 提供了软中断的运行情况；**

**/proc/interrupts 提供了硬中断的运行情况。**

运行下面的命令，查看 /proc/softirqs 文件的内容，你就可以看到各种类型软中断在不同 CPU 上的累积运行次数：

```

[root@localhost ~]# cat /proc/softirqs
                    CPU0       CPU1       CPU2       CPU3
          HI:          0          0          0          1
       TIMER:    7162062   14778047    4809839   12123095
      NET_TX:          1     190439          3          2
      NET_RX:    2011702    2542076     524800    1462328
       BLOCK:      16202      20016      70112     443356
BLOCK_IOPOLL:          0          0          0          0
     TASKLET:     145402         80         11       1135
       SCHED:    2100823    4027617    2452375    5694855
     HRTIMER:          0          0          0          0
         RCU:    4138367    7838168    2880635    6074916
[root@localhost ~]#

```

Linux 中的软中断包括网络收发、定时、调度、RCU 锁等各种类型。

**在 Linux 中，每个 CPU 都对应一个软中断内核线程，名字是 ksoftirqd/CPU 编号**



扩展阅读参考：

<https://xinqiu.gitbooks.io/linux-insides-cn/content/Interrupts/linux-interrupts-9.html>



## 10 | 案例篇：系统的软中断CPU使用率升高，我该怎么办？

观察 /proc/softirqs 文件的内容，你就能知道各种软中断类型的次数。这里的各类软中断次数，是系统运行以来的累积中断次数。

所以我们直接查看文件内容，得到的只是累积中断次数，对这里的问题并没有直接参考意义。因为，**这些中断次数的变化速率才是我们需要关注的**。

sar  可以用来查看系统的网络收发情况，还有一个好处是，不仅可以观察网络收发的吞吐量（BPS，每秒收发的字节数），还可以观察网络收发的 PPS，即每秒收发的网络帧数。

```

01:56:44 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s
01:56:44 PM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00
01:56:44 PM virbr0-nic      0.00      0.00      0.00      0.00      0.00      0.00      0.00
01:56:44 PM    virbr0      0.00      0.00      0.00      0.00      0.00      0.00      0.00
01:56:44 PM eno16780032      5.26     10.53      0.59      1.42      0.00      0.00      0.00

Average:        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s
Average:           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00
Average:    virbr0-nic      0.00      0.00      0.00      0.00      0.00      0.00      0.00
Average:       virbr0      0.00      0.00      0.00      0.00      0.00      0.00      0.00
Average:    eno16780032      4.41      1.32      0.33      0.17      0.00      0.00      0.00

```

对于 sar 的输出界面：

第一列：表示报告的时间。

第二列：IFACE 表示网卡。

第三、四列：rxpck/s 和 txpck/s 分别表示每秒接收、发送的网络帧数，也就是  PPS。

第五、六列：rxkB/s 和 txkB/s 分别表示每秒接收、发送的千字节数，也就是  BPS。



软中断 CPU 使用率（softirq）升高是一种很常见的性能问题。虽然软中断的类型很多，但实际生产中，**我们遇到的性能瓶颈大多是网络收发类型的软中断，特别是网络接收的软中断。**



一个软中断的例子：

<https://blog.huoding.com/2013/10/30/296>



## 11 | 套路篇：如何迅速分析出系统CPU的瓶颈在哪里？

### CPU 性能指标

#### CPU使用率

CPU 使用率描述了非空闲时间占总 CPU 时间的百分比，根据 CPU 上运行任务的不同，又被分为用户 CPU、系统 CPU、等待 I/O CPU、软中断和硬中断等。

用户 CPU 使用率，包括用户态 CPU 使用率（user）和低优先级用户态 CPU 使用率（nice），表示 CPU 在用户态运行的时间百分比。

用户 CPU 使用率高，通常说明有应用程序比较繁忙。

系统 CPU 使用率，表示 CPU 在内核态运行的时间百分比（不包括中断）。

系统 CPU 使用率高，说明内核比较繁忙。

等待 I/O 的 CPU 使用率，通常也称为 iowait，表示等待 I/O 的时间百分比。

iowait 高，通常说明系统与硬件设备的 I/O 交互时间比较长。

软中断和硬中断的 CPU 使用率，分别表示内核调用软中断处理程序、硬中断处理程序的时间百分比。它们的使用率高，通常说明系统发生了大量的中断。

除了上面这些，还有在虚拟化环境中会用到的窃取 CPU 使用率（steal）和客户 CPU 使用率（guest），分别表示被其他虚拟机占用的 CPU 时间百分比，和运行客户虚拟机的 CPU 时间百分比。

#### 平均负载

平均负载（Load Average），也就是系统的平均活跃进程数。它反应了系统的整体负载情况，主要包括三个数值，分别指过去 1 分钟、过去 5 分钟和过去 15 分钟的平均负载。

理想情况下，平均负载等于逻辑 CPU 个数，这表示每个 CPU 都恰好被充分利用。如果平均负载大于逻辑 CPU 个数，就表示负载比较重了。

#### 进程上下文切换

进程上下文切换，包括：无法获取资源而导致的自愿上下文切换；被系统强制调度导致的非自愿上下文切换。

#### CPU 缓存的命中率



### 性能工具

#### 根据指标找工具

**第一个维度，从 CPU 的性能指标出发。也就是说，当你要查看某个性能指标时，要清楚知道哪些工具可以做到。**

![根据指标找工具](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/02-01.png)

#### 根据工具找指标

**第二个维度，从工具出发。也就是当你已经安装了某个工具后，要知道这个工具能提供哪些指标。**

![根据工具查指标](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/02-02.png)

#### 如何迅速分析 CPU 的性能瓶颈

虽然 CPU 的性能指标比较多，但要知道，既然都是描述系统的 CPU 性能，它们就不会是完全孤立的，很多指标间都有一定的关联。

**想弄清楚性能指标的关联性，就要通晓每种性能指标的工作原理。**

这也是为什么我在介绍每个性能指标时，都要穿插讲解相关的系统原理，希望你能记住这一点。

举个例子，用户 CPU 使用率高，我们应该去排查进程的用户态而不是内核态。

因为用户 CPU 使用率反映的就是用户态的 CPU 使用情况，而内核态的 CPU 使用情况只会反映到系统 CPU 使用率上。

你看，有这样的基本认识，我们就可以缩小排查的范围，省时省力。

所以，为了缩小排查范围，**我通常会先运行几个支持指标较多的工具，如 top、vmstat 和 pidstat 。**为什么是这三个工具呢？仔细看看下面这张图，你就清楚了

**三步排查大法**

![三步排查法](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/02-03.png)

这三个命令，几乎包含了所有重要的 CPU 性能指标，比如：

**从 top 的输出可以得到各种 CPU 使用率以及僵尸进程和平均负载等信息。**

**从 vmstat 的输出可以得到上下文切换次数、中断次数、运行状态和不可中断状态的进程数。**

**从 pidstat 的输出可以得到进程的用户 CPU 使用率、系统 CPU 使用率、以及自愿上下文切换和非自愿上下文切换情况。**

## 12 | 套路篇：CPU 性能优化的几个思路

### 性能优化方法论

**先问问这三个问题：**

首先，既然要做性能优化，那要怎么判断它是不是有效呢？特别是优化后，到底能提升多少性能呢？

第二，性能问题通常不是独立的，如果有多个性能问题同时发生，你应该先优化哪一个呢？

第三，提升性能的方法并不是唯一的，当有多种方法可以选择时，你会选用哪一种呢？是不是总选那个最大程度提升性能的方法就行了呢？

### 怎么评估性能优化的效果？

性能评估“三步走”：

**确定性能的量化指标。**

**测试优化前的性能指标。**

**测试优化后的性能指标。**



**如何选择指标来评估量化性能呢？**

我的建议是不要局限在单一维度的指标上，你**至少要从应用程序和系统资源这两个维度**，分别选择不同的指标。

比如，以 Web 应用为例：

应用程序的维度，我们可以用**吞吐量和请求延迟**来评估应用程序的性能。

系统资源的维度，我们可以用 **CPU 使用率**来评估系统的 CPU 使用情况。



**性能测试注意点**

第一，**要避免性能测试工具干扰应用程序的性能**。简单说，测试工具和被测试对象要独立部署。

第二，**避免外部环境的变化影响性能指标的评估**。这要求优化前、后的应用程序，都运行在相同配置的机器上，并且它们的外部依赖也要完全一致。



**性能问题的优化选择**

第一，如果发现是系统资源达到了瓶颈，比如 CPU 使用率达到了 100%，那么首先优化的一定是系统资源使用问题。完成系统资源瓶颈的优化后，我们才要考虑其他问题。

第二，针对不同类型的指标，首先去优化那些由瓶颈导致的，性能指标变化幅度最大的问题。比如产生瓶颈后，用户 CPU 使用率升高了 10%，而系统 CPU 使用率却升高了 50%，这个时候就应该首先优化系统 CPU 的使用。



### CPU 优化

#### 应用程序优化

**编译器优化**：很多编译器都会提供优化选项，适当开启它们，在编译阶段你就可以获得编译器的帮助，来提升性能。比如， gcc 就提供了优化选项 -O2，开启后会自动对应用程序的代码进行优化。

**算法优化**：使用复杂度更低的算法，可以显著加快处理速度。比如，在数据比较大的情况下，可以用 O(nlogn) 的排序算法（如快排、归并排序等），代替 O(n^2) 的排序算法（如冒泡、插入排序等）。

**异步处理：**使用异步处理，可以避免程序因为等待某个资源而一直阻塞，从而提升程序的并发处理能力。比如，把轮询替换为事件通知，就可以避免轮询耗费 CPU 的问题。

**多线程代替多进程：**前面讲过，相对于进程的上下文切换，线程的上下文切换并不切换进程地址空间，因此可以降低上下文切换的成本。

**善用缓存：**经常访问的数据或者计算过程中的步骤，可以放到内存中缓存起来，这样在下次用时就能直接从内存中获取，加快程序的处理速度。

#### 系统优化

**CPU 绑定：**把进程绑定到一个或者多个 CPU 上，可以提高 CPU 缓存的命中率，减少跨 CPU 调度带来的上下文切换问题。

**CPU 独占：**跟 CPU 绑定类似，进一步将 CPU 分组，并通过 CPU 亲和性机制为其分配进程。这样，这些 CPU 就由指定的进程独占，换句话说，不允许其他进程再来使用这些 CPU。

**优先级调整：**使用 nice 调整进程的优先级，正值调低优先级，负值调高优先级。在这里，适当降低非核心应用的优先级，增高核心应用的优先级，可以确保核心应用得到优先处理。

**为进程设置资源限制：**使用 Linux cgroups 来设置进程的 CPU 使用上限，可以防止由于某个应用自身的问题，而耗尽系统资源。

**NUMA（Non-Uniform Memory Access）优化**：支持 NUMA 的处理器会被划分为多个 node，每个 node 都有自己的本地内存空间。NUMA 优化，其实就是让 CPU 尽可能只访问本地内存。

**中断负载均衡：**无论是软中断还是硬中断，它们的中断处理程序都可能会耗费大量的 CPU。**开启 irqbalance 服务或者配置 smp_affinity，就可以把中断处理过程自动负载均衡到多个 CPU 上**。

#### 千万避免过早优化

高德纳的名言， **“过早优化是万恶之源”**

![Knuth's optimization principle](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/02-04.jpeg)

扩展阅读：

<https://smartbear.com/blog/develop/dont-cut-yourself-code-optimization-as-a-double-ed/>



**性能优化最好是逐步完善，动态进行，不追求一步到位，而要首先保证能满足当前的性能要求。当发现性能不满足要求或者出现性能瓶颈时，再根据性能评估的结果，选择最重要的性能问题进行优化。**



## 13 | 答疑（一）：无法模拟出 RES 中断的问题，怎么办？



在实际生产环境中，即使你很可能需要运行老版本的操作系统，还没有权限安装新的软件包，你也可以查看 proc 文件系统，获取自己想要的指标。

**初学时，你最好试着去理解性能工具的原理，或者熟悉了使用方法后，再回过头重新学习原理。**这样，即使是在无法安装新工具的环境中，你仍然可以从 proc 文件系统或者其他地方，获得同样的指标，进行有效的分析。



有些同学会拿 pidstat 中的 %wait 跟 top 中的 iowait% （缩写为 wa）对比，其实这是没有意义的，因为它们是完全不相关的两个指标。

**pidstat 中， %wait 表示进程等待 CPU 的时间百分比。**

**top 中 ，iowait% 则表示等待 I/O 的 CPU 时间百分比。**

回忆一下我们学过的进程状态，你应该记得，等待 CPU 的进程已经在 CPU 的就绪队列中，处于运行状态；而等待 I/O 的进程则处于不可中断状态。



**授之以鱼，不如授之以渔**。**我们专栏的学习核心，一定是教会你性能分析的原理和思路**，性能工具只是我们的路径和手段。

特别是，当你发现某些工具的输出不符合常识时，一定记住，**第一时间查文档弄明白**。

**学习是一个“从薄到厚再变薄”的过程**，我们从细节知识入手开始学习，积累到一定程度，需要整理成一个体系来记忆，这其中还要不断地对这个体系进行细节修补。有疑问、有反思才可以达到最佳的学习效果。



## 14 | 答疑（二）：如何用perf工具分析Java程序？

**很多性能工具确实会对系统性能有一定影响**。就拿 perf 来说，它需要在内核中跟踪内核栈的各种事件，那么不可避免就会带来一定的性能损失。

这一点，虽然对大部分应用来说，没有太大影响，但对特定的某些应用（比如那些对时钟周期特别敏感的应用），可能就是灾难了。

所以，使用性能工具时，确实应该考虑工具本身对系统性能的影响。而这种情况，就需要你**了解这些工具的原理**。比如，

perf 这种动态追踪工具，会给系统带来一定的性能损失。

vmstat、pidstat 这些直接读取 proc 文件系统来获取指标的工具，不会带来性能损失。





## 扩展阅读

### 代码优化概要

<https://coolshell.cn/articles/2967.html>

1. **使用 一个profiler。**
2. **查看程序执行时的汇编码。**

使用这两个技术的人将会成功地写出运行快的代码，不会使用这两个技术的人则不行。



使用Profiler时，重点需要关注：

1）花时间多的函数以优化其算法，

2）调用次数巨多的函数——如果一个函数每秒被调用300K次，你只需要优化出0.001毫秒，那也是相当大的优化。这就是作者所谓的1%的代码占用了99%的CPU时间



最基本的方法就是使用一个profiler和愿意去查看一下其汇编代码以找到程序的瓶颈。只有找到了程序的瓶颈，此时才是真正在思考如何去改进的时候，比如思考一个更好的算法，使用更快的语言优化，等等



### 性能调优攻略

<https://coolshell.cn/articles/7490.html>



### **图书推荐**

关于性能优化的书籍，我最喜欢的其实正是他写的那本 《Systems Performance: Enterprise and the Cloud》。这本书也出了中文版，名字是**《性能之巅：洞悉系统、企业与云计算》**。

留言中老师还推荐了：**《深入Linux内核架构》**

