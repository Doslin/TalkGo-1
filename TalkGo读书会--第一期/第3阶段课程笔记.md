# 第 3 阶段课程笔记

## 15 | 基础篇：Linux内存是怎么工作的？

### 虚拟地址空间

虚拟地址空间的内部又被分为**内核空间和用户空间**两部分，不同字长（也就是单个 CPU 指令可以处理数据的最大长度）的处理器，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，我画了两张图来分别表示它们的虚拟地址空间，如下所示：

![虚拟地址空间](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/03-01.png)

通过这里可以看出，32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间。而 64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。

**内存映射，其实就是将虚拟内存地址映射到物理内存地址。**为了完成内存映射，内核为每个进程都维护了一张页表，记录虚拟地址与物理地址的映射关系。**页表实际上存储在 CPU 的内存管理单元 MMU 中**，这样，正常情况下，处理器就可以直接通过硬件，找出要访问的内存。

备注：第一阶段笔记资料参考“MMU和TLB”



### 虚拟内存空间分布

![虚拟内存空间](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/03-02.png)

用户空间内存，从低到高分别是五种不同的内存段。

只读段，包括代码和常量等。

数据段，包括全局变量等。

堆，包括动态分配的内存，从低地址开始向上增长。

文件映射段，包括动态库、共享内存等，从高地址开始向下增长。

栈，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。

在这五个内存段中，**堆和文件映射段的内存是动态分配的。**比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。



### 内存分配与回收

#### 内存分配

malloc() 是 C 标准库提供的内存分配函数，对应到系统调用上，有两种实现方式，即 brk() 和 mmap()。

对小块内存（小于 128K），C 标准库使用 brk() 来分配，也就是通过移动堆顶的位置来分配内存。这些内存释放后并不会立刻归还系统，而是被缓存起来，这样就可以重复使用。

而大块内存（大于 128K），则直接使用内存映射 mmap() 来分配，也就是在文件映射段找一块空闲内存分配出去。



**备注：**

**此处malloc分配内存是通过标准库用户空间的调用，内核空间采用kmalloc分配内存，此时会涉及slab分配管理。**



#### 内存回收

在发现内存紧张时，系统就会通过一系列机制来回收内存，比如下面这三种方式：

1. 回收缓存，比如使用 LRU（Least Recently Used）算法，回收最近使用最少的内存页面；
2. 回收不常访问的内存，把不常用的内存通过交换分区直接写到磁盘中；
3. 杀死进程，内存紧张时系统还会通过 OOM（Out of Memory），直接杀掉占用大量内存的进程。



OOM（Out of Memory），其实是内核的一种保护机制。它监控进程的内存使用情况，并且使用 oom_score 为每个进程的内存使用情况进行评分：

**一个进程消耗的内存越大，oom_score 就越大；**

**一个进程运行占用的 CPU 越多，oom_score 就越小。**

**备注：可以通过 /proc 文件系统，手动设置进程的 oom_adj ，从而调整进程的 oom_score。**



### 查看内存

#### free命令

```
[root@localhost ~]# free -h
              total        used        free      shared  buff/cache   available
Mem:           3.7G        835M        748M         17M        2.2G        2.6G
Swap:          3.2G          0B        3.2G
[root@localhost ~]#

```

每列含义：

第一列，total 是总内存大小；

第二列，used 是已使用内存的大小，包含了共享内存；

第三列，free 是未使用内存的大小；

第四列，shared 是共享内存的大小；

第五列，buff/cache 是缓存和缓冲区的大小；

最后一列，available 是新进程可用内存的大小。



#### top命令

```
Tasks: 257 total,   1 running, 256 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.2 us,  0.1 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  3881744 total,   765692 free,   856672 used,  2259380 buff/cache
KiB Swap:  3354620 total,  3354620 free,        0 used.  2687692 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 2731 root      20   0 2359604 217728  48164 S   0.7  5.6   7:36.40 gnome-shell
23579 root      20   0  148120   5564   4144 S   0.3  0.1   0:00.49 sshd
23646 root      20   0  157852   2400   1536 R   0.3  0.1   0:00.07 top
    1 root      20   0  193700   6852   4068 S   0.0  0.2   0:33.44 systemd

```

**跟内存相关的几列数据，比如 VIRT、RES、SHR 以及 %MEM 等。**

VIRT 是进程虚拟内存的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内。

**RES 是常驻内存的大小，也就是进程实际使用的物理内存大小，但不包括 Swap 和共享内存。**

SHR 是共享内存的大小，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等。

%MEM 是进程使用物理内存占系统总内存的百分比。



## 16 | 基础篇：怎么理解内存中的Buffer和Cache？

#### free解释

从 free 的手册中，你可以看到 buffer 和 cache 的说明。

**Buffers 是内核缓冲区用到的内存，对应的是  /proc/meminfo 中的 Buffers 值。C**

**ache 是内核页缓存和 Slab 用到的内存，对应的是  /proc/meminfo 中的 Cached 与 SReclaimable 之和。**



#### **proc文件系统解释**

Buffers 是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大（20MB 左右）。这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等。

Cached 是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。

SReclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。

<https://www.kernel.org/doc/Documentation/filesystems/proc.txt>



Buffer 既可以用作“将要写入磁盘数据的缓存”，也可以用作“从磁盘读取数据的缓存”。

Cache 既可以用作“从文件读取数据的页缓存”，也可以用作“写文件的页缓存”。

**简单来说，Buffer 是对磁盘数据的缓存，而 Cache 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中。**



## 17 | 案例篇：如何利用系统缓存优化程序的运行效率？

Buffers 和 Cache 可以极大提升系统的 I/O 性能。通常，我们用缓存命中率，来衡量缓存的使用效率。命中率越高，表示缓存被利用得越充分，应用程序的性能也就越好。



**Buffers 和 Cache 都是操作系统来管理的，应用程序并不能直接控制这些缓存的内容和生命周期。所以，在应用程序开发中，一般要用专门的缓存组件，来进一步提升性能。**



**扩展阅读**

CoolShell 与程序员相关的CPU缓存知识

<https://coolshell.cn/articles/20793.html>



## 18 | 案例篇：内存泄漏了，我该如何定位和处理？

对应用程序来说，动态内存的分配和回收，是既核心又复杂的一个逻辑功能模块。管理内存的过程中，也很容易发生各种各样的“事故”，

**比如，没正确回收分配后的内存，导致了泄漏。**

**访问的是已分配内存边界外的地址，导致程序异常退出，等等。**



实际应用程序就复杂多了。比如说，

malloc() 和 free() 通常并不是成对出现，而是需要你，在每个异常处理路径和成功路径上都释放内存 。

在多线程程序中，一个线程中分配的内存，可能会在另一个线程中访问和释放。

更复杂的是，在第三方的库函数中，隐式分配的内存可能需要应用程序显式释放。



思考：

内存泄露工作中采用valgrind进行检测，只要能复现故障，通常问题都能快速定位。另外可以通过**Valgrind的Massif工具**可以直观查看。

参考：

<https://blog.csdn.net/fengbingchun/article/details/83279163>



## 19 | 案例篇：为什么系统的Swap变高了（上）

### 内存回收

#### 文件页内存回收

前面讲过的缓存和缓冲区，就属于可回收内存。它们在内存管理中，通常被叫做文件页（File-backed Page）。

大部分文件页，都可以直接回收。但是，**那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页）**，就得先写入磁盘，然后才能进行内存释放。

这些脏页，一般可以通过两种方式写入磁盘。

可以在应用程序中，通过系统调用 fsync  ，把脏页同步到磁盘中；

也可以交给系统，由内核线程 pdflush 负责这些脏页的刷新。



#### 匿名页回收

应用程序动态分配的堆内存，也就是我们在内存管理中说到的匿名页（Anonymous Page）。

Swap 把这些不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。



### Swap 原理

Swap 说白了就是把一块磁盘空间或者一个本地文件（以下讲解以磁盘为例），当成内存来使用。它包括换出和换入两个过程。

所谓换出，就是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存。

而换入，则是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来。

**Swap 其实是把系统的可用内存变大了。这样，即使服务器的内存不足，也可以运行大内存的应用程序。**

#### kswapd0内核线程

除了直接内存回收，还有一个专门的内核线程用来定期回收内存，也就是 kswapd0。为了衡量内存的使用情况，kswapd0 定义了三个内存阈值（watermark，也称为水位），分别是

页最小阈值（pages_min）、页低阈值（pages_low）和页高阈值（pages_high）。剩余内存，则使用 pages_free 表示。

#### swappiness 选项

Linux 提供了一个  /proc/sys/vm/swappiness 选项，用来调整使用 Swap 的积极程度。swappiness 的范围是 0-100，数值越大，越积极使用 Swap，也就是更倾向于回收匿名页；数值越小，越消极使用 Swap，也就是更倾向于回收文件页



**调整 Swap 积极程度的权重，即使你把它设置成 0，当剩余内存 + 文件页小于页高阈值时，还是会发生 Swap。**

**备注：**若想禁止Swap不发生，则需要关闭swap。



## 20 | 案例篇：为什么系统的Swap变高了？（下）

通常，降低 Swap 的使用，可以提高系统的整体性能。要怎么做呢？这里，我也总结了几种常见的降低方法。

1. **禁止 Swap**，现在服务器的内存足够大，所以除非有必要，禁用 Swap 就可以了。随着云计算的普及，大部分云平台中的虚拟机都默认禁止 Swap。
2. 如果实在需要用到 Swap，可以**尝试降低 swappiness 的值**，减少内存回收时 Swap 的使用倾向。
3. 响应延迟敏感的应用，如果它们可能在开启 Swap 的服务器中运行，你还可以**用库函数 mlock() 或者 mlockall() 锁定内存**，阻止它们的内存换出。







## 21 | 套路篇：如何“快准狠”找到系统内存的问题？

### 内存性能指标

![内存性能指标](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/03-03.png)

### 内存性能工具

![内存性能工具](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/03-04.png)

### 内存性能工具与指标联系

![内存性能工具与指标联系](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/03-05.png)



### 如何迅速分析内存的性能瓶颈

**为了迅速定位内存问题，我通常会先运行几个覆盖面比较大的性能工具，比如 free、top、vmstat、pidstat 等。**具体的分析思路主要有这几步。

先用 free 和 top，查看系统整体的内存使用情况。

再用 vmstat 和 pidstat，查看一段时间的趋势，从而判断出内存问题的类型。

最后进行详细分析，比如内存分配分析、缓存 / 缓冲区分析、具体进程的内存使用分析等。



![迅速分析内存性能瓶颈](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/03-06.png)

### 内存优化思路

常见的优化思路有这么几种。

1. 最好禁止 Swap。如果必须开启 Swap，降低 swappiness 的值，减少内存回收时 Swap 的使用倾向。
2. 减少内存的动态分配。比如，可以使用内存池、大页（HugePage）等。
3. 尽量使用缓存和缓冲区来访问数据。比如，可以使用堆栈明确声明内存空间，来存储需要缓存的数据；或者用 Redis 这类的外部缓存组件，优化数据的访问。
4. 使用 cgroups 等方式限制进程的内存使用情况。这样，可以确保系统内存不会被异常进程耗尽。
5. 通过 /proc/pid/oom_adj ，调整核心应用的 oom_score。这样，可以保证即使内存紧张，核心应用也不会被 OOM 杀死。



## 关联知识



### 锁定内存

在一些应用程序中将一个进程的虚拟内存的部分或全部锁进内存以确保它们总是位于物理内存中是非常有用的。之所以需要这样做的一个原因是它可以**提高性能**。**对被锁住的分页的访问可以确保永远不会因为分页故障而发生延迟。**这对于那些需要确保快速响应时间的应用程序来讲是很有用的。

在 2.6.9 之前的Linux 内核中，只有特权进程（CAP_IPC_LOCK）才能给内存加锁，RLIMIT_MEMLOCK 软资源限制为一个特权进程能够锁住的字节数设定一个上限。
**从 Linux 2.6.9 开始，内存加锁模型发生了变化，即允许非特权进程给一小段内存进行加锁。**

1.  特权进程能够锁住的内存数量是没有限制的（即 RLIMIT_MEMLOCK 会被忽略）；
2. 非特权进程能够锁住的内存数量上限由软限制 RLIMIT_MEMLOCK 定义。

软和硬RLIMIT_MEMLOCK 限制的默认值都是8 个分页（即在x86-32 上是32768 字节）。



**通过查看Linux 特有的/proc/PID/status 文件中的VmLck 条目能够找出一个进程当前已经锁住的内存数量。**



**Name**

mlock, munlock, mlockall, munlockall - lock and unlock memory

**Synopsis**

```
#include <sys/mman.h>

int mlock(const void *addr, size_t len);
int munlock(const void *addr, size_t len);

int mlockall(int flags);
int munlockall(void);
```

**Description**

**mlock**() and **mlockall**() respectively lock part or all of the calling process's virtual address space into RAM, preventing that memory from being paged to the swap area. **munlock**() and **munlockall**() perform the converse operation, respectively unlocking part or all of the calling process's virtual address space, so that pages in the specified virtual address range may once more to be swapped out if required by the kernel memory manager. Memory locking and unlocking are performed in units of whole pages.



更多参考：

《Unix系统编程手册》章节 50.2 内存锁：mlock()和mlockatt()

<https://linux.die.net/man/2/mlockall>

### 大页（HugePage）

HugePage，就是指的大页内存管理方式。与传统的4kb的普通页管理方式相比，HugePage为管理大内存(8GB以上)更为高效。

通过启用“大内存页”，系统具只需要处理较少的页面映射表，从而减少访问/维护它们的开销。

```
[root@localhost ~]# grep Huge /proc/meminfo
AnonHugePages:    354304 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
[root@localhost ~]#
```



SHM_HUGETLB（自Linux 2.6 起）
特权（CAP_IPC_LOCK）进程能够使用这个标记创建一个使用巨页（huge page）的共享内存段。巨页是很多现代硬件架构提供的一项特性用来管理使用超大分页尺寸的内存。（如x86-32 允许使用4MB 的分页大小来替代4KB 的分页大小。）在那些拥有大量内存的系统上并且应用程序需要使用大量内存块时，**使用巨页可以降低硬件内存管理单元的超前转换缓冲器（translationlook-aside buffer，TLB）中的条目数量**。这之所以会带来益处是因为TLB 中的条目通常是一种稀缺资源。更多信息可参考内核源文件Documentation/vm/hugetlbpage.txt。

参考更多：

<https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt>



### pmap分析方法



```
# 使用grep查找Pss指标后，再用awk计算累加值
$ grep Pss /proc/[1-9]*/smaps | awk '{total+=$2}; END {printf "%d kB\n", total }'
```

