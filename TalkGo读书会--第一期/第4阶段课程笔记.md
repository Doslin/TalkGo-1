# 第 4 阶段课程笔记

## 23 | 基础篇：Linux 文件系统是怎么工作的？

### Linux 文件系统

Linux 文件系统为每个文件都分配两个数据结构，索引节点（index node）和目录项（directory entry）。它们主要用来记录文件的元信息和目录结构。

**索引节点，简称为 inode，用来记录文件的元数据**，比如 inode 编号、文件大小、访问权限、修改日期、数据的位置等。索引节点和文件一一对应，它跟文件内容一样，都会被持久化存储到磁盘中。所以记住，索引节点同样占用磁盘空间。

**目录项，简称为 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的关联关系**。多个关联的目录项，就构成了文件系统的目录结构。不过，不同于索引节点，目录项是由内核维护的一个内存数据结构，所以通常也被叫做**目录项缓存**。



目录项、索引节点以及文件数据的关系

![目录项、索引节点以及文件数据的关系](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/04-01.png)



### 虚拟文件系统

![虚拟文件系统](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/04-02.png)

 Linux 在各种文件系统实现上，又抽象了一层虚拟文件系统 VFS，它定义了一组，所有文件系统都支持的，数据结构和标准接口。

VFS 内部又通过目录项、索引节点、逻辑块以及超级块等数据结构，来管理文件。

目录项，记录了文件的名字，以及文件与其他目录项之间的目录关系。

索引节点，记录了文件的元数据。

逻辑块，是由连续磁盘扇区构成的最小读写单元，用来存储文件数据。

超级块，用来记录文件系统整体的状态，如索引节点和逻辑块的使用情况等。

**其中，目录项是一个内存缓存；而超级块、索引节点和逻辑块，都是存储在磁盘中的持久化数据。**



## 24 | 基础篇：Linux 磁盘I/O是怎么工作的（上）

### 硬盘分类

根据存储介质的不同，常见磁盘可以分为两类：机械磁盘和固态磁盘。

第一类，机械磁盘，也称为硬盘驱动器（Hard Disk Driver），通常缩写为 HDD。机械磁盘的最小读写单位是扇区，一般大小为 512 字节。

第二类，固态磁盘（Solid State Disk），通常缩写为 SSD，由固态电子元器件组成。而固态磁盘的最小读写单位是页，通常大小是 4KB、8KB 等。

### 通用块层

为了减小不同块设备的差异带来的影响，Linux 通过一个统一的通用块层，来管理各种不同的块设备。

通用块层，其实是处在文件系统和磁盘驱动中间的一个块设备抽象层。它主要有两个功能 。

第一个功能跟虚拟文件系统的功能类似。向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序。

第二个功能，通用块层还会给文件系统和应用程序发来的 I/O 请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。其中，对 I/O 请求排序的过程，也就是我们熟悉的 I/O 调度。

Linux 内核支持四种 I/O 调度算法，分别是 NONE、NOOP、CFQ 以及 DeadLine。

### I/O栈

![ I/O 栈全景图](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/04-03.png)

根据这张 I/O 栈的全景图，我们可以更清楚地理解，存储系统 I/O 的工作原理。

**文件系统层，包括虚拟文件系统和其他各种文件系统的具体实现**。它为上层的应用程序，提供标准的文件访问接口；对下会通过通用块层，来存储和管理磁盘数据。

**通用块层，包括块设备 I/O 队列和 I/O 调度器**。它会对文件系统的 I/O 请求进行排队，再通过重新排序和请求合并，然后才要发送给下一级的设备层。设备层，包括存储设备和相应的驱动程序，负责最终物理设备的 I/O 操作。

**存储系统的 I/O ，通常是整个系统中最慢的一环。所以， Linux 通过多种缓存机制来优化 I/O 效率。**

比方说，为了优化文件访问的性能，采用页缓存、索引节点缓存、目录项缓存等多种缓存机制，减少对下层块设备的直接调用。

同样的，为了优化块设备的访问效率，使用缓冲区来缓存块设备的数据。



## 25 | 基础篇：Linux 磁盘I/O是怎么工作的（下）

### 磁盘性能指标

衡量磁盘性能的基本指标：**使用率、饱和度、IOPS、吞吐量以及响应时间等**

1. 使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈。
2. 饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求。
3. IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。
4. 吞吐量，是指每秒的 I/O 请求大小。
5. 响应时间，是指 I/O 请求从发出到收到响应的间隔时间。

**这里要注意的是，使用率只考虑有没有 I/O，而不考虑 I/O 的大小。换句话说，当使用率是 100% 的时候，磁盘依然有可能接受新的 I/O 请求。**

我们在为应用程序的服务器选型时，**要先对磁盘的 I/O 性能进行基准测试**，以便可以准确评估，磁盘性能是否可以满足应用程序的需求。

测试出，不同 I/O 大小（一般是 512B 至 1MB 中间的若干值）分别在随机读、顺序读、随机写、顺序写等各种场景下的性能情况。



### 磁盘 I/O 观测

#### iostat

iostat 是最常用的磁盘 I/O 性能观测工具，它提供了每个磁盘的使用率、IOPS、吞吐量等各种常见的性能指标，当然，这些指标实际上来自  /proc/diskstats。

1. **%util  ，就是我们前面提到的磁盘 I/O 使用率；**
2. **r/s+  w/s  ，就是 IOPS；**
3. **rkB/s+wkB/s ，就是吞吐量；**
4. **r_await+w_await ，就是响应时间。**

特别的，**饱和度没法直接观测到，一般是通过实际观测值跟基准测试结果对比来分析。**



生产环境上的一个示例：

```
Linux 3.10.0-327.22.2.el7.x86_64 (i-288g158bq)  06/20/2020      _x86_64_        (2 CPU)

Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
vda               0.00     7.52    0.77    6.01    77.76   184.95    77.47     0.04    5.64    4.16    5.83   0.95   0.64
vdb               0.00    16.88    0.16   41.94     3.82   247.63    11.94     0.09    2.03    2.92    2.03   1.73   7.28

```



### 进程 I/O 观测

####  pidstat 

从 pidstat 的输出你能看到，它可以实时查看每个进程的 I/O 情况，包括下面这些内容。

用户 ID（UID）和进程 ID（PID）  。

每秒读取的数据大小（kB_rd/s） ，单位是 KB。

每秒发出的写请求数据大小（kB_wr/s） ，单位是 KB。

每秒取消的写请求数据大小（kB_ccwr/s） ，单位是 KB。

块 I/O 延迟（iodelay），包括等待同步块 I/O 和换入块 I/O 结束的时间，单位是时钟周期。



## 26 | 案例篇：如何找出狂打日志的“内鬼”？

碰到这种“狂打日志”的场景时，你可以用 iostat、strace、lsof 等工具来定位狂打日志的进程，找出相应的日志文件，再通过应用程序的接口，调整日志级别来解决问题。

**思考：**

线上生产环境查证问题时，可能会依赖相关日志，所以功能开发设计时就要提前考虑故障定位与日志级别的分级打印，避免提供打印级别后日志过多影响生成环境负载。



## 27 | 案例篇：为什么我的磁盘I/O延迟很高？

首先，我们用 top、iostat，分析了系统的 CPU 和磁盘使用情况。我们发现了磁盘 I/O 瓶颈，也知道了这个瓶颈是案例应用导致的。

接着，我们试着照搬上一节案例的方法，用 strace 来观察进程的系统调用，不过这次很不走运，没找到任何 write 系统调用。

于是，我们又用了新的工具，借助动态追踪工具包 bcc 中的 filetop 和 opensnoop ，找出了案例应用的问题，发现这个根源是大量读写临时文件。



**专栏精选留言：**

写文件是由子线程执行的，所以直接strace跟踪进程没有看到write系统调用，可以通过pstree查看进程的线程信息，再用strace跟踪。或者，通过**strace -fp pid 跟踪所有线程**。



## 28 | 案例篇：一个SQL查询要15秒，这是怎么回事？

我们先是通过 top、iostat 分析了系统的 CPU 和磁盘使用情况，发现了磁盘的 I/O 瓶颈。

接着，我们借助 pidstat ，发现瓶颈是 mysqld 导致的。

紧接着，我们又通过 strace、lsof，找出了 mysqld 正在读的文件。同时，根据文件的名字和路径，我们找出了 mysqld 正在操作的数据库和数据表。

综合这些信息，我们判断，这是一个没有利用索引导致的慢查询问题。

于是，我们登录到 MySQL 命令行终端，用数据库分析工具进行验证，发现 MySQL 查询语句访问的字段，果然没有索引。所以，增加索引，就可以解决案例的性能问题了。

**MySQL 的 MyISAM 引擎，主要依赖系统缓存加速磁盘 I/O 的访问。可如果系统中还有其他应用同时运行， MyISAM 引擎很难充分利用系统缓存。缓存可能会被其他应用程序占用，甚至被清理掉。**



## 29 | 案例篇：Redis响应严重延迟，如何解决？

1. 先观察 CPU、内存和磁盘 I/O 等的使用情况，top命令；
2. 执行下面的 iostat 命令，查看有没有 I/O 性能问题。
3. 通过pidstat 命令，定位哪个进程的 I/O 情况
4. 用 strace+lsof 组合，看看 redis-server 到底在写什么



Redis 提供了两种数据持久化的方式，分别是快照和追加文件。

**快照方式**，会按照指定的时间间隔，生成数据的快照，并且保存到磁盘文件中。

**追加文件**，则是用在文件末尾追加记录的方式，对 Redis 写入的数据，依次进行持久化，所以它的持久化也更安全。此外，它还提供了一个用 appendfsync 选项设置 fsync 的策略，确保写入的数据都落到磁盘中，具体选项包括 always、everysec、no 等。

always 表示，每个操作都会执行一次 fsync，是最为安全的方式；

everysec 表示，每秒钟调用一次 fsync ，这样可以保证即使是最坏情况下，也只丢失 1 秒的数据；

而 no 表示交给操作系统来处理。





## 关联知识

### Ext4与XFS

<https://computingforgeeks.com/ext4-vs-xfs-complete-comparison/>



### VFS

<https://www.kernel.org/doc/html/latest/filesystems/vfs.html>