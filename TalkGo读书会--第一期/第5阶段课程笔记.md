# 第 5 阶段课程笔记

## 30 | 套路篇：如何迅速分析出系统I/O的瓶颈在哪里？

### 性能指标

#### 文件系统 I/O 性能指标

首先，最容易想到的是**存储空间的使用情况，包括容量、使用量以及剩余空间等**。

除了数据本身的存储空间，还有一个容易忽略的是索引节点的使用情况，它也包括容量、使用量以及剩余量等三个指标。

其次，你应该想到的是前面多次提到过的**缓存使用情况，包括页缓存、目录项缓存、索引节点缓存以及各个具体文件系统（如 ext4、XFS 等）的缓存**。

#### 磁盘 I/O 性能指标

四个核心的磁盘 I/O 指标。

使用率，是指磁盘忙处理 I/O 请求的百分比。过高的使用率（比如超过 60%）通常意味着磁盘 I/O 存在性能瓶颈。

IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。

吞吐量，是指每秒的 I/O 请求大小。

响应时间，是指从发出 I/O 请求到收到响应的间隔时间。



![I/O性能指标](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/05-01.png)

### 性能指标和工具的联系

**第一个维度，从文件系统和磁盘 I/O 的性能指标出发。换句话说，当你想查看某个性能指标时，要清楚知道，哪些工具可以做到。**

![根据指标找工具](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/05-02.png)



**第二个维度，从工具出发。也就是当你已经安装了某个工具后，要知道这个工具能提供哪些指标。**

![根据工具查指标](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/05-03.png)



#### 如何迅速分析 I/O 的性能瓶颈

1. 先用 iostat 发现磁盘 I/O 性能瓶颈；
2. 再借助 pidstat ，定位出导致瓶颈的进程；
3. 随后分析进程的 I/O 行为；
4. 最后，结合应用程序的原理，分析这些 I/O 的来源。



![文件系统和磁盘 I/O 性能分析的思路图谱](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/05-04.png)



## 31 | 套路篇：磁盘 I/O 性能优化的几个思路

### I/O 基准测试

**fio（Flexible I/O Tester）正是最常用的文件系统和磁盘 I/O 性能基准测试工具**。它提供了大量的可定制化选项，可以用来测试，裸盘或者文件系统在各种场景下的 I/O 性能，包括了不同块大小、不同 I/O 引擎以及是否使用缓存等场景。

**fio 支持 I/O 的重放**。借助前面提到过的 blktrace，再配合上 fio，就可以实现对应用程序 I/O 模式的基准测试。你需要先用 blktrace ，记录磁盘设备的 I/O 访问情况；然后使用 fio ，重放 blktrace 的记录。



### I/O 性能优化

#### 应用程序优化

几种方式来优化应用程序的 I/O 性能。

第一，可以用追加写代替随机写，减少寻址开销，加快 I/O 写的速度。

第二，可以借助缓存 I/O ，充分利用系统缓存，降低实际 I/O 的次数。

第三，可以在应用程序内部构建自己的缓存，或者用 Redis 这类外部缓存系统。

第四，在需要频繁读写同一块磁盘空间时，可以用 mmap 代替 read/write，减少内存的拷贝次数。

第五，在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用 fsync() 取代 O_SYNC。

第六，在多个应用程序共享相同磁盘时，为了保证 I/O 不被某个应用完全占用，推荐你使用 cgroups 的 I/O 子系统，来限制进程 / 进程组的 IOPS 以及吞吐量。

最后，在使用 CFQ 调度器时，可以用 ionice 来调整进程的 I/O 调度优先级，特别是提高核心应用的 I/O 优先级。



#### 文件系统优化

第一，你可以根据实际负载场景的不同，选择最适合的文件系统。比如 Ubuntu 默认使用 ext4 文件系统，而 CentOS 7 默认使用 xfs 文件系统。

第二，在选好文件系统后，还可以进一步优化文件系统的配置选项，包括文件系统的特性（如 ext_attr、dir_index）、日志模式（如 journal、ordered、writeback）、挂载选项（如 noatime）等等。

第三，可以优化文件系统的缓存。

最后，在**不需要持久化时，你还可以用内存文件系统 tmpfs，以获得更好的 I/O 性能** 。tmpfs 把数据直接保存在内存中，而不是磁盘中。比如 /dev/shm/ ，就是大多数 Linux 默认配置的一个内存文件系统，它的大小默认为总内存的一半。

#### 磁盘优化

第一，最简单有效的优化方法，就是换用性能更好的磁盘，比如用 SSD 替代 HDD。

第二，我们可以使用 RAID ，把多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列。

第三，针对磁盘和应用程序 I/O 模式的特征，我们可以**选择最适合的 I/O 调度算法**。比方说，SSD 和虚拟机中的磁盘，通常用的是 noop 调度算法。而数据库应用，我更推荐使用 deadline 算法。

第四，我们可以对应用程序的数据，进行**磁盘级别的隔离**。比如，我们可以为日志、数据库等 I/O 压力比较重的应用，配置单独的磁盘。

第五，在顺序读比较多的场景中，我们可以**增大磁盘的预读数据**。

第六，我们可以优化内核块设备 I/O 的选项。

最后，要注意，**磁盘本身出现硬件错误**，也会导致 I/O 性能急剧下降。。



## 32 | 答疑（四）：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系

一般来说，**我并不建议，把应用程序的性能优化完全建立在系统缓存上。**还是那句话，最好能在应用程序的内部分配内存，构建完全自主控制的缓存，比如 MySQL 的 InnoDB 引擎，就同时缓存了索引和数据；或者，可以使用第三方的缓存应用，比如 Memcached、Redis 等。



## 33 | 关于 Linux 网络，你必须知道这些（上）

### 网络模型

#### OSI 网络模型

应用层，负责为应用程序提供统一的接口。

表示层，负责把数据转换成兼容接收系统的格式。

会话层，负责维护计算机之间的通信连接。

传输层，负责为数据加上传输表头，形成数据包。

网络层，负责数据的路由和转发。

数据链路层，负责 MAC 寻址、错误侦测和改错。

物理层，负责在物理网络中传输数据帧。



#### TCP/IP 模型

应用层，负责向用户提供一组应用程序，比如 HTTP、FTP、DNS 等。

传输层，负责端到端的通信，比如 TCP、UDP 等。

网络层，负责网络包的封装、寻址和路由，比如 IP、ICMP 等。

网络接口层，负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。



#### TCP/IP 与 OSI 模型的关系

![TCP/IP 与 OSI 模型的关系](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/05-05.png)

### Linux 网络栈

![Linux网络协议栈](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/05-06.png)

### Linux 网络收发流程

![Linux网络收发流程](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/05-06.png)



## 34 | 关于 Linux 网络，你必须知道这些（下）

### 性能指标

**通常用带宽、吞吐量、延时、PPS（Packet Per Second）等指标衡量网络的性能**。

带宽，表示链路的最大传输速率，单位通常为 b/s （比特 / 秒）。

吞吐量，表示单位时间内成功传输的数据量，单位通常为 b/s（比特 / 秒）或者 B/s（字节 / 秒）。吞吐量受带宽限制，而吞吐量 / 带宽，也就是该网络的使用率。

延时，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。。

PPS，是 Packet Per Second（包 / 秒）的缩写，表示以网络包为单位的传输速率。PPS 通常用来评估网络的转发能力。

除了这些指标，网络的可用性（网络能否正常通信）、并发连接数（TCP 连接数量）、丢包率（丢包百分比）、重传率（重新传输的网络包比例）等也是常用的性能指标。



### 网络配置命令

**ifconfig**

**ip**

**ss**

**netstat**

**sar**

**ping**



## 35 | 基础篇：C10K 和 C1000K 回顾

C10K 和 C1000K 的首字母 C 是 Client 的缩写。C10K 就是单机同时处理 1 万个请求（并发连接 1 万）的问题，而 C1000K 也就是单机支持处理 100 万个请求（并发连接 100 万）的问题。

### I/O 模型优化

第一种，使用非阻塞 I/O 和水平触发通知，比如使用 select 或者 poll。

第二种，使用非阻塞 I/O 和边缘触发通知，比如 epoll。

第三种，使用异步 I/O（Asynchronous I/O，简称为 AIO）。

### C10M

要解决这个问题，最重要就是跳过内核协议栈的冗长路径，把网络包直接送到要处理的应用程序那里去。这里有两种常见的机制，**DPDK 和 XDP**。

1. 需要用 XDP 方式，在内核协议栈之前，先处理网络包。
2. 或基于 DPDK ，直接跳过网络协议栈，在用户空间通过轮询的方式处理。

**参考：**

<https://feisky.gitbooks.io/sdn/linux/XDP/design.html>

<https://feisky.gitbooks.io/sdn/dpdk/introduction.html>



## 36 | 套路篇：怎么评估系统的网络性能？

根据 TCP/IP 协议栈的原理，不同协议层关注的性能重点不完全一样，也就对应不同的性能测试方法。

比如，在应用层，你可以使用 wrk、Jmeter 等模拟用户的负载，测试应用程序的每秒请求数、处理延迟、错误数等；

而在传输层，则可以使用 iperf 等工具，测试 TCP 的吞吐情况；

再向下，你还可以用 Linux 内核自带的 pktgen ，测试服务器的 PPS。



### 性能测试命令

iperf 和 netperf 都是最常用的网络性能测试工具，测试 TCP 和 UDP 的吞吐量。

它们都以客户端和服务器通信的方式，测试一段时间内的平均吞吐量。

