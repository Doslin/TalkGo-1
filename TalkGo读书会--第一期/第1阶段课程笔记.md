# 第 1 阶段课程笔记

## 02 ｜ 基础篇：到底应该怎么理解“平均负载”

### 什么是平均负载

平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系

**man uptime**

```
DESCRIPTION
       uptime  gives  a one line display of the following information.  The current time, how long the system has been running, how many users are currently logged on, and the system load averages for
       the past 1, 5, and 15 minutes.

   This is the same information contained in the header line displayed by w(1).

   System load averages is the average number of processes that are either in a runnable or uninterruptable state.  A process in a runnable state is either using the CPU or waiting to use the CPU.
   A  process  in uninterruptable state is waiting for some I/O access, eg waiting for disk.  The averages are taken over the three time intervals.  Load averages are not normalized for the number of CPUs in a system, so a load average of 1 means a single CPU system is loaded all the time while on a 4 CPU system it means it was idle 75% of the time.
```



所谓可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。**不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程**。



**man top中关于Process Status字段的解释：**

```
       20. S  --  Process Status
           The status of the task which can be one of:
               D = uninterruptible sleep
               R = running
               S = sleeping
               T = stopped by job control signal
               t = stopped by debugger during trace
               Z = zombie
```



**man ps中关于Process Status字段**

```
PROCESS STATE CODES
       Here are the different values that the s, stat and state output specifiers (header "STAT" or "S") will display to describe the state of a process:

               D    uninterruptible sleep (usually IO)
               R    running or runnable (on run queue)
               S    interruptible sleep (waiting for an event to complete)
               T    stopped by job control signal
               t    stopped by debugger during the tracing
               W    paging (not valid since the 2.6.xx kernel)
               X    dead (should never be seen)
               Z    defunct ("zombie") process, terminated but not reaped by its parent
```



### 平均负载与CPU使用率的区别

平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，它不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如：

1. CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；
2. I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高；
3. 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。



### TASK_INTERRUPTIBLE 与 TASK_KILLABLE

<https://www.ibm.com/developerworks/cn/linux/l-task-killable/index.html>

Linux Kernel 2.6.25 引入了一种新的进程睡眠状态，`TASK_KILLABLE`：当进程处于这种可以终止的新睡眠状态中，它的运行原理类似于 `TASK_UNINTERRUPTIBLE`，只不过可以响应致命信号



![进程状态](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/2.gif)



## 03 | 基础篇：经常说的 CPU 上下文切换是什么意思？（上）

### CPU上下文切换

**上下文切换的过程：**
      (1)记录当前任务的上下文(即寄存器和计算器等所有的状态)；
      (2)找到新任务的上下文并加载；
      (3)切换到新任务的程序计算器位置，恢复其任务。

根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是**进程上下文切换、线程上下文切换以及中断上下文切换。**

### **内核态与用户态**

根据《深入Linux内核架构》1.3章节关于内核态与用户态有如下描述：

```
英特尔处理器区分4种特权级别，但Linux只使用两种不同的状态：核心态和用户状态。两种状态的关键差别在于对高于TASK_SIZE的内存区域的访问。简而言之，在用户状态禁止访问内核空间。用户进程不能操作或读取内核空间中的数据，也无法执行内核空间中的代码。这是内核的专用领域。这种机制可防止进程无意间修改彼此的数据而造成相互干扰。
```

**简而言之，在用户状态禁止访问内核空间**

从用户态切换到内核态的方法：

1）系统调用；

2）异常，如缺页异常；

3）中断；



### 三种上下文切换的区别

**进程上下文切换**

指从一个进程切换到另一个进程
(1)进程运行态为内核运行态和进程运行态。内核空间态资源包括内核的堆栈、寄存器等；用户空间态资源包括虚拟内存、栈、变量、正文、数据等
(2)系统调用(软中断)在内核态完成的，需要进行2次CPU上下文切换(用户空间-->内核空间-->用户空间)，不涉及用户态资源，也不会切换进程。
(3)进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，进程的上下文不仅包括了用户空间的资源，也包括内核空间资源。

**触发进程上下文切换的场景**

1. 根据调度策略，将CPU时间划片为对应的时间片，当时间片耗尽，当前进程必须挂起。
2. 资源不足的，在获取到足够资源之前进程挂起。
3. 进程sleep挂起进程。
4. 高优先级进程导致当前进度挂起
5. 硬件中断，导致当前进程挂起

**线程上下文切换**
不同进程之间的线程上下文切换，其过程和进程上下文切换大致相同。

进程内部的线程进上下文切换。不需要切换进程的用户资源，只需要切换线程私有的数据和寄存器等。这会比进程上下文进程切换消耗的资源少，所以多线程相比多进程的优势。
**中断上下文切换**
快速响应硬件的事件，中断处理会打断进程的正常调度和执行。同一CPU内，硬件中断优先级高于进程。切换过程类似于系统调用的时候，不涉及到用户运行态资源。但大量的中断上下文切换同样可能引发性能问题。

**特别的，在进程上下文中运行的主要区别是，在中断上下文中运行不能访问虚拟地址空间中的用户空间部分。因为中断可能随机发生，中断发生时可能是任一用户进程处于活动状态，由于该进程基本上与中断的原因无关，因此内核无权访问当前用户空间的内容。在中断上下文中运行时，内核必须比正常情况更加谨慎，例如，不能进入睡眠状态。**



**思考：**

进程上下文切换，是指从一个进程切换到另一个进程运行。而系统调用过程中一直是同一个进程在运行。

进程上下文切换、线程上下文切换以及中断上下文切换 三者的开销比较如何？

进程上下文切换 > 线程上下文切换 >中断上下文切换



## 04 | 基础篇：经常说的 CPU 上下文切换是什么意思？（下）

### vmstat命令

vmstat 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。

### 上下文切换

这两个概念你一定要牢牢记住，因为它们意味着不同的性能问题：

所谓自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。对应 cswch  ，表示每秒自愿上下文切换（voluntary context switches）的次数。

而非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。对应 nvcswch  ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。

### /proc/interrupts

通过读取文件 **/proc/interrupts** 获取各种类型的中断次数。

```bash
# -d 参数表示高亮显示变化的区域
watch -d cat /proc/interrupts 
```

RES （重调度中断）。RES 中断类型表示，唤醒空闲状态的 CPU 来调度新任务，是多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，也被称为处理器间中断（Inter-Processor Interrupts，IPI）。当它对应的值变化很快时，说明存在过多的任务要调度，CPU 资源可能紧张。


## 05 | 基础篇：某个应用的CPU使用率居然达到100%，我该怎么办？

**碰到 CPU 使用率升高的问题，你可以借助 top、pidstat 等工具，确认引发 CPU 性能问题的来源；再使用 perf 等工具，排查出引起性能问题的具体函数。**



思路：

CPU性能定位通过perf 打点即可，通过CPU火焰图可以直观查看。关于火焰图，还有内存火焰图、Off-CPU火焰图，有时间要总结汇总下。

<https://zhuanlan.zhihu.com/p/54276509>



## 06 | 案例篇：系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？

系统的 CPU 使用率，不仅包括进程用户态和内核态的运行，还包括中断处理、等待 I/O 以及内核线程等。所以，当你发现系统的 CPU 使用率很高的时候，不一定能找到相对应的高 CPU 使用率的进程。

**金句：**

**在怀疑性能工具出问题前，最好还是先用其他工具交叉确认一下。**

**bruceding留言：**

对于内核函数的调试，4.0 的内核可以使用 eBPF 工具，2.6 或者 4.0 以下的工具，使用 systemtap。perf 是基于采样的原理。本文的例子 execsnoop 可以替换成 https://sourceware.org/systemtap/SystemTap_Beginners_Guide/threadtimessect.html。

sar -w 或者 sar -w 1 也能直观的看到每秒生成线程或者进程的数量。Brendan Gregg 确实是这个领域的大师，贡献了很多的技术理念和实践经验。他的**《性能之巅》** 可以和本课对比着看，会有更多的理解。

思考：

1）订购的《性能之巅》到货，希望结合大师的图书提升Linux性能优化功底。

2）动态跟踪技术要抽出时间学习并实践

参考：<https://sourceware.org/systemtap/SystemTap_Beginners_Guide/>



## 关联知识点

### CPU核数与线程数

- 一台完整的计算机可能包含一到多个物理 cpu
- 从单个物理 cpu （physical cpu）的角度看，其可能是单核心、双核心甚至多核心的
- 从单个核心（core）的角度看，还有 SMT / HT 等技术让每个 core 对计算机操作系统而言用起来像多个物理 core 差不多

总的逻辑 cpu 数 = 物理 cpu 数 * 每颗物理 cpu 的核心数 * 每个核心的超线程数



查看物理 cpu 数：

> ```
> cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l
> ```

查看每个物理 cpu 中 核心数(core 数)：

> ```
> cat /proc/cpuinfo | grep "cpu cores" | uniq
> ```

查看总的逻辑 cpu 数（processor 数）：

> ```
> cat /proc/cpuinfo| grep "processor"| wc -l
> ```

查看 cpu 型号：

> ```
> cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c
> ```



以下面的Linux环境为例，

总的逻辑 cpu 数 = 物理 cpu 数 * 每颗物理 cpu 的核心数 * 每个核心的超线程数

物理CPU = 2 ，每颗物理 cpu 的核心数 = 8，每个核心的超线程数 = 1

因此逻辑CPU数为16，对应lscpu命令对应如下字段：

```
CPU(s):                16
On-line CPU(s) list:   0-15
Thread(s) per core:    1
Core(s) per socket:    8
Socket(s):             2
```



完整命令输出如下：

```
[root@localhost ~]# lscpu
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                16
On-line CPU(s) list:   0-15
Thread(s) per core:    1
Core(s) per socket:    8
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 63
Model name:            Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz
Stepping:              2
CPU MHz:               1200.000
CPU max MHz:           2400.0000
CPU min MHz:           1200.0000
BogoMIPS:              4794.34
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              20480K
NUMA node0 CPU(s):     0-3,8-11
NUMA node1 CPU(s):     4-7,12-15

[root@localhost ~]# cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l
2
[root@localhost ~]# cat /proc/cpuinfo | grep "cpu cores" | uniq
cpu cores       : 8
[root@localhost ~]# cat /proc/cpuinfo| grep "processor"| wc -l
16
[root@localhost ~]# cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c
     16  Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz
[root@localhost ~]#

```

**参考材料**

<https://www.cnblogs.com/bugutian/p/6138880.html>

<https://zhuanlan.zhihu.com/p/86855590>



### L1\L2\L3 Cache 与TLB

#### MMU与TLB

根据wiki的解释：

A **translation lookaside buffer** (**TLB**) is a memory [cache](https://en.wikipedia.org/wiki/CPU_cache) that is used to reduce the time taken to access a user memory location.[[1\]](https://en.wikipedia.org/wiki/Translation_lookaside_buffer#cite_note-tlbsurvey-1)[[2\]](https://en.wikipedia.org/wiki/Translation_lookaside_buffer#cite_note-ostep-1-2) It is a part of the chip's [memory-management unit](https://en.wikipedia.org/wiki/Memory_management_unit) (MMU). The TLB stores the recent translations of [virtual memory](https://en.wikipedia.org/wiki/Virtual_memory) to [physical memory](https://en.wikipedia.org/wiki/Physical_memory) and can be called an address-translation cache. A TLB may reside between the [CPU](https://en.wikipedia.org/wiki/Central_processing_unit) and the [CPU cache](https://en.wikipedia.org/wiki/CPU_cache), between CPU cache and the main memory or between the different levels of the multi-level cache. The majority of desktop, laptop, and server processors include one or more TLBs in the memory-management hardware, and it is nearly always present in any processor that utilizes [paged](https://en.wikipedia.org/wiki/Paging) or [segmented](https://en.wikipedia.org/wiki/Memory_segmentation) [virtual memory](https://en.wikipedia.org/wiki/Virtual_memory).

![MMU与TLB](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/03.png)



![MMU与TLB](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/04.png)



MMU是CPU芯片的一部分，而TLB快表是MMU的一部分。TLB(Translation Lookaside Buffer)，专门用于改进虚拟地址到物理地址转换速度的缓存。**其访问速度非常快，和寄存器相当，比L1访问还快。**

**TLB hit time: 0.5 – 1 clock cycle** 

**L1 cache: 3 cycles**

**L2 cache: 11 cycles**

**L3 cache: 25 cycles**

**Main Memory: 100 cycles**

有了TLB之后，CPU访问某个虚拟内存地址的过程如下

**1、CPU产生一个虚拟地址**

**2、MMU从TLB中获取页表，翻译成物理地址**

**3、MMU把物理地址发送给L1/L2/L3/内存**

**4、L1/L2/L3/内存将地址对应数据返回给CPU**

#### L1、L2、L3缓存



#### CPU Cache与TLB的区别

First thing first. **CPU Cache** is a fast memory which is used to improve latency of fetching information from Main memory (RAM) to CPU registers. So CPU Cache sits between Main memory and CPU. And this cache stores information temporarily so that the next access to the same information is faster. A CPU cache which used to store executable instructions, it’s called Instruction Cache (I-Cache). A CPU cache which is used to store data, it’s called Data Cache (D-Cache). So I-Cache and D-Cache speeds up fetching time for instructions and data respectively. A modern processor contains both I-Cache and D-Cache. For completeness, let us discuss about D-cache hierarchy as well. D-Cache is typically organized in a hierarchy i.e. Level 1 data cache, Level 2 data cache etc.. It should be noted that L1 D-Cache is faster/smaller/costlier as compared to L2 D-Cache. But the basic idea of ‘*CPU cache*‘ is to speed up instruction/data fetch time from Main memory to CPU.

**Translation Lookaside Buffer (i.e. TLB)** is required only if Virtual Memory is used by a processor. In short, TLB speeds up translation of virtual address to physical address by storing page-table in a faster memory. In fact, TLB also sits between CPU and Main memory. Precisely speaking, TLB is used by MMU when virtual address needs to be translated to physical address. By keeping this mapping of virtual-physical addresses in a fast memory, access to page-table improves. It should be noted that page-table (which itself is stored in RAM) keeps track of where virtual pages are stored in the physical memory. In that sense, TLB also can be considered as a cache of the page-table.

**TLB is about ‘speeding up address translation for Virtual memory’ so that page-table needn’t to be accessed for every address. CPU Cache is about ‘speeding up main memory access latency’ so that RAM isn’t accessed always by CPU.** 

![Cache与TLB](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/05.png)



#### 如何查看L1、L2、L3缓存大小

```
[claa@localhost ~]$ getconf -a | grep -i cache
LEVEL1_ICACHE_SIZE                 32768
LEVEL1_ICACHE_ASSOC                8
LEVEL1_ICACHE_LINESIZE             64
LEVEL1_DCACHE_SIZE                 32768
LEVEL1_DCACHE_ASSOC                8
LEVEL1_DCACHE_LINESIZE             64
LEVEL2_CACHE_SIZE                  262144
LEVEL2_CACHE_ASSOC                 8
LEVEL2_CACHE_LINESIZE              64
LEVEL3_CACHE_SIZE                  20971520
LEVEL3_CACHE_ASSOC                 20
LEVEL3_CACHE_LINESIZE              64
LEVEL4_CACHE_SIZE                  0
LEVEL4_CACHE_ASSOC                 0
LEVEL4_CACHE_LINESIZE              0
[claa@localhost ~]$ lscpu | grep -i cache
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              20480K

```

#### TLB的命中查看

```
[root@localhost ~]# perf stat -e dTLB-loads,dTLB-load-misses,iTLB-loads,iTLB-load-misses -p 25178

^C
 Performance counter stats for process id '25178':

       153,182,445      dTLB-loads
         4,266,611      dTLB-load-misses          #    2.79% of all dTLB cache hits   (99.90%)
            69,109      iTLB-loads                                                    (99.90%)
           962,590      iTLB-load-misses          # 1392.86% of all iTLB cache hits   (99.90%)

      40.817393340 seconds time elapsed


[root@localhost ~]#

```



#### 参考材料

<https://cseweb.ucsd.edu/classes/su09/cse120/lectures/Lecture7.pdf>

https://zhuanlan.zhihu.com/p/79607142 

<https://www.geeksforgeeks.org/whats-difference-between-cpu-cache-and-tlb/>