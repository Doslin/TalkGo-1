# 第 1 阶段课程笔记

## 02 ｜ 基础篇：到底应该怎么理解“平均负载”

### 什么是平均负载

平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系

**man uptime**

```
DESCRIPTION
       uptime  gives  a one line display of the following information.  The current time, how long the system has been running, how many users are currently logged on, and the system load averages for
       the past 1, 5, and 15 minutes.

   This is the same information contained in the header line displayed by w(1).

   System load averages is the average number of processes that are either in a runnable or uninterruptable state.  A process in a runnable state is either using the CPU or waiting to use the CPU.
   A  process  in uninterruptable state is waiting for some I/O access, eg waiting for disk.  The averages are taken over the three time intervals.  Load averages are not normalized for the number of CPUs in a system, so a load average of 1 means a single CPU system is loaded all the time while on a 4 CPU system it means it was idle 75% of the time.
```



所谓可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。**不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程**。



**man top中关于Process Status字段的解释：**

```
       20. S  --  Process Status
           The status of the task which can be one of:
               D = uninterruptible sleep
               R = running
               S = sleeping
               T = stopped by job control signal
               t = stopped by debugger during trace
               Z = zombie
```



**man ps中关于Process Status字段**

```
PROCESS STATE CODES
       Here are the different values that the s, stat and state output specifiers (header "STAT" or "S") will display to describe the state of a process:

               D    uninterruptible sleep (usually IO)
               R    running or runnable (on run queue)
               S    interruptible sleep (waiting for an event to complete)
               T    stopped by job control signal
               t    stopped by debugger during the tracing
               W    paging (not valid since the 2.6.xx kernel)
               X    dead (should never be seen)
               Z    defunct ("zombie") process, terminated but not reaped by its parent
```



### 平均负载与CPU使用率的区别

平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，它不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如：

1. CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；
2. I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高；
3. 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。



### TASK_INTERRUPTIBLE 与 TASK_KILLABLE

<https://www.ibm.com/developerworks/cn/linux/l-task-killable/index.html>

Linux Kernel 2.6.25 引入了一种新的进程睡眠状态，`TASK_KILLABLE`：当进程处于这种可以终止的新睡眠状态中，它的运行原理类似于 `TASK_UNINTERRUPTIBLE`，只不过可以响应致命信号



![进程状态](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/2.gif)



### L1\L2\L3 Cache 与TLB

#### MMU与TLB

根据wiki的解释：

A **translation lookaside buffer** (**TLB**) is a memory [cache](https://en.wikipedia.org/wiki/CPU_cache) that is used to reduce the time taken to access a user memory location.[[1\]](https://en.wikipedia.org/wiki/Translation_lookaside_buffer#cite_note-tlbsurvey-1)[[2\]](https://en.wikipedia.org/wiki/Translation_lookaside_buffer#cite_note-ostep-1-2) It is a part of the chip's [memory-management unit](https://en.wikipedia.org/wiki/Memory_management_unit) (MMU). The TLB stores the recent translations of [virtual memory](https://en.wikipedia.org/wiki/Virtual_memory) to [physical memory](https://en.wikipedia.org/wiki/Physical_memory) and can be called an address-translation cache. A TLB may reside between the [CPU](https://en.wikipedia.org/wiki/Central_processing_unit) and the [CPU cache](https://en.wikipedia.org/wiki/CPU_cache), between CPU cache and the main memory or between the different levels of the multi-level cache. The majority of desktop, laptop, and server processors include one or more TLBs in the memory-management hardware, and it is nearly always present in any processor that utilizes [paged](https://en.wikipedia.org/wiki/Paging) or [segmented](https://en.wikipedia.org/wiki/Memory_segmentation) [virtual memory](https://en.wikipedia.org/wiki/Virtual_memory).

![MMU与TLB](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/03.png)



![MMU与TLB](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/04.png)



MMU是CPU芯片的一部分，而TLB快表是MMU的一部分。TLB(Translation Lookaside Buffer)，专门用于改进虚拟地址到物理地址转换速度的缓存。**其访问速度非常快，和寄存器相当，比L1访问还快。**

**TLB hit time: 0.5 – 1 clock cycle** 

**L1 cache: 3 cycles**

**L2 cache: 11 cycles**

**L3 cache: 25 cycles**

**Main Memory: 100 cycles**

有了TLB之后，CPU访问某个虚拟内存地址的过程如下

**1、CPU产生一个虚拟地址**

**2、MMU从TLB中获取页表，翻译成物理地址**

**3、MMU把物理地址发送给L1/L2/L3/内存**

**4、L1/L2/L3/内存将地址对应数据返回给CPU**

#### L1、L2、L3缓存



#### CPU Cache与TLB的区别

First thing first. **CPU Cache** is a fast memory which is used to improve latency of fetching information from Main memory (RAM) to CPU registers. So CPU Cache sits between Main memory and CPU. And this cache stores information temporarily so that the next access to the same information is faster. A CPU cache which used to store executable instructions, it’s called Instruction Cache (I-Cache). A CPU cache which is used to store data, it’s called Data Cache (D-Cache). So I-Cache and D-Cache speeds up fetching time for instructions and data respectively. A modern processor contains both I-Cache and D-Cache. For completeness, let us discuss about D-cache hierarchy as well. D-Cache is typically organized in a hierarchy i.e. Level 1 data cache, Level 2 data cache etc.. It should be noted that L1 D-Cache is faster/smaller/costlier as compared to L2 D-Cache. But the basic idea of ‘*CPU cache*‘ is to speed up instruction/data fetch time from Main memory to CPU.

**Translation Lookaside Buffer (i.e. TLB)** is required only if Virtual Memory is used by a processor. In short, TLB speeds up translation of virtual address to physical address by storing page-table in a faster memory. In fact, TLB also sits between CPU and Main memory. Precisely speaking, TLB is used by MMU when virtual address needs to be translated to physical address. By keeping this mapping of virtual-physical addresses in a fast memory, access to page-table improves. It should be noted that page-table (which itself is stored in RAM) keeps track of where virtual pages are stored in the physical memory. In that sense, TLB also can be considered as a cache of the page-table.

**TLB is about ‘speeding up address translation for Virtual memory’ so that page-table needn’t to be accessed for every address. CPU Cache is about ‘speeding up main memory access latency’ so that RAM isn’t accessed always by CPU.** 

![Cache与TLB](https://github.com/hwangyungping/TalkGo/blob/master/TalkGo读书会--第一期/PIC/05.png)



#### 如何查看L1、L2、L3缓存大小

```
[claa@localhost ~]$ getconf -a | grep -i cache
LEVEL1_ICACHE_SIZE                 32768
LEVEL1_ICACHE_ASSOC                8
LEVEL1_ICACHE_LINESIZE             64
LEVEL1_DCACHE_SIZE                 32768
LEVEL1_DCACHE_ASSOC                8
LEVEL1_DCACHE_LINESIZE             64
LEVEL2_CACHE_SIZE                  262144
LEVEL2_CACHE_ASSOC                 8
LEVEL2_CACHE_LINESIZE              64
LEVEL3_CACHE_SIZE                  20971520
LEVEL3_CACHE_ASSOC                 20
LEVEL3_CACHE_LINESIZE              64
LEVEL4_CACHE_SIZE                  0
LEVEL4_CACHE_ASSOC                 0
LEVEL4_CACHE_LINESIZE              0
[claa@localhost ~]$ lscpu | grep -i cache
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              20480K

```

#### TLB的命中查看

```
[root@localhost ~]# perf stat -e dTLB-loads,dTLB-load-misses,iTLB-loads,iTLB-load-misses -p 25178

^C
 Performance counter stats for process id '25178':

       153,182,445      dTLB-loads
         4,266,611      dTLB-load-misses          #    2.79% of all dTLB cache hits   (99.90%)
            69,109      iTLB-loads                                                    (99.90%)
           962,590      iTLB-load-misses          # 1392.86% of all iTLB cache hits   (99.90%)

      40.817393340 seconds time elapsed


[root@localhost ~]#

```



#### 参考材料

<https://cseweb.ucsd.edu/classes/su09/cse120/lectures/Lecture7.pdf>

https://zhuanlan.zhihu.com/p/79607142 

<https://www.geeksforgeeks.org/whats-difference-between-cpu-cache-and-tlb/>